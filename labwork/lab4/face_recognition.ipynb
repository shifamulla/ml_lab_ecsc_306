{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# loading positive images and labels\n",
    "\n",
    "\n",
    "images1=[]    # To store list of images\n",
    "\n",
    "label=[]      # To Store Labels\n",
    "\n",
    "files=glob.glob(\"/home/c2/Downloads/paul/*.jpg\")  # reads all the file_names from the specified folder into  files[] list \n",
    "\n",
    "for file in files:               #for loop for reading images into images1[] list and appends label of the image into label_positive[] list\n",
    "    image1=cv2.imread(file) \n",
    "    resized_image = cv2.resize(image1, (112, 92))\n",
    "    images1.append(resized_image)      \n",
    "    label.append([1])\n",
    "\n",
    "    \n",
    "#plt.imshow(images1[1])       #displaying the first image of the list images1[]\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------loading of positive images is done ----------------------------------------------------\n",
    "\n",
    "\n",
    "#-------------------------------------loading  negative images and labels----------------------------------------------------\n",
    "\n",
    "files=glob.glob(\"/home/c2/Downloads/ian/*.jpg\")  #reads all the file_names in the specified folder into  files[] list \n",
    "\n",
    "#print files     # prints all file names in the folder\n",
    "#print len(files)   # prints number of files have been red\n",
    "\n",
    "for file in files:               #for loop for reading images into images1[] list and appends label of the image into label_positive[] list\n",
    "    image1=cv2.imread(file) \n",
    "    resized_image = cv2.resize(image1, (112, 92))\n",
    "    images1.append(resized_image)      \n",
    "    label.append([0])\n",
    "\n",
    "    \n",
    "#plt.imshow(images1[16])       #displaying the first image of the list images1[]\n",
    "#plt.show()\n",
    "\n",
    "print((\"labels \",label))\n",
    "\n",
    "\n",
    "#-------------------------------------loading of Negative images is done ----------------------------------------------------\n",
    "\n",
    "\n",
    "images2=np.array(images1)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "columns = 4\n",
    "for i in range(14):\n",
    "    plt.subplot(14 / columns + 1, columns, i + 1)\n",
    "    plt.imshow(images2[i,:,:,:])\n",
    "plt.show()   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#images2=np.array(images1)\n",
    "labels=np.array(label)\n",
    "print((images2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (images2.shape[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=(None,images2.shape[1],images2.shape[2],images2.shape[3]))   # Tenssorflow container to hold input data \n",
    "y = tf.placeholder(tf.float32, shape=[None,labels.shape[1]])         # Tensorflow container to hold  target data \n",
    "\n",
    "\n",
    "#------------------------------------------First Convolution Layer----------------------------------------------------\n",
    "\n",
    "W=tf.Variable(tf.random_normal([5, 5, 3, 32]))       # using 32 filters of 5x5 each having dimension 3    \n",
    "b=tf.Variable(tf.random_normal([32]))                # 1x32 bais values  \n",
    "\n",
    "x2 = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') \n",
    "x2 = tf.nn.bias_add(x2, b)\n",
    "conv_output=tf.nn.relu(x2)\n",
    "maxpool_output=tf.nn.max_pool(conv_output,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')  # New image 56x46 \n",
    "\n",
    "\n",
    "#------------------------------------------Second Convolution Layer----------------------------------------------------\n",
    "\n",
    "W1=tf.Variable(tf.random_normal([3, 3, 32, 64]))  # using 64 filters of 3x3 each having dimension of 32  \n",
    "b1=tf.Variable(tf.random_normal([64]))            # 64 bais values\n",
    "\n",
    "x3 = tf.nn.conv2d(maxpool_output, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "x3 = tf.nn.bias_add(x3, b1)\n",
    "conv_output2=tf.nn.relu(x3)\n",
    "maxpool_output2=tf.nn.max_pool(conv_output2,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "#-------------------------------------------Third Convolution Layer---------------------------------------------------\n",
    "\n",
    "W2=tf.Variable(tf.random_normal([3, 3, 64,16]))  # using 16 filters of 3x3 each having dimension of 16 \n",
    "b2=tf.Variable(tf.random_normal([16]))\n",
    "\n",
    "x4 = tf.nn.conv2d(maxpool_output2, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "x4 = tf.nn.bias_add(x4, b2)\n",
    "conv_output3=tf.nn.relu(x4)\n",
    "maxpool_output3=tf.nn.max_pool(conv_output3,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------Fully Connected Network---------------------------------------------------\n",
    "\n",
    "\n",
    "fc_weights1=tf.Variable(tf.truncated_normal([14*12*16, 1024],stddev=0.05))  #   14*12*16 input features \n",
    "fc_bias1=tf.Variable(tf.random_normal([1024]))               # 1024 bias   \n",
    "\n",
    "fc_weights2=tf.Variable(tf.random_normal([1024, 2048]))      # Hidden Layer accept 1024 \n",
    "fc_bias2=tf.Variable(tf.random_normal([2048]))               #2048 bias\n",
    "\n",
    "fc_weights3=tf.Variable(tf.random_normal([2048, 128]))       \n",
    "fc_bias3=tf.Variable(tf.random_normal([128]))\n",
    "\n",
    "fc_weights5=tf.Variable(tf.random_normal([128, 8]))\n",
    "fc_bias5=tf.Variable(tf.random_normal([8]))\n",
    "\n",
    "fc_weights4=tf.Variable(tf.random_normal([8,1]))\n",
    "fc_bias4=tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "fc1 = tf.reshape(maxpool_output3, [-1, fc_weights1.get_shape().as_list()[0]])\n",
    "fc1 = tf.add(tf.matmul(fc1, fc_weights1), fc_bias1)\n",
    "fc1 = tf.nn.sigmoid(fc1)\n",
    "\n",
    "\n",
    "fcl2 = tf.add(tf.matmul(fc1, fc_weights2), fc_bias2)\n",
    "fcl2=tf.nn.sigmoid(fcl2)\n",
    "\n",
    "\n",
    "fcl3 = tf.add(tf.matmul(fcl2, fc_weights3), fc_bias3)\n",
    "fcl3=tf.nn.sigmoid(fcl3)\n",
    "\n",
    "fcl4 = tf.add(tf.matmul(fcl3, fc_weights5), fc_bias5)\n",
    "fcl4=tf.nn.sigmoid(fcl4)\n",
    "\n",
    "\n",
    "# Output, class prediction\n",
    "out = tf.add(tf.matmul(fcl4, fc_weights4), fc_bias4)\n",
    "out1=tf.nn.sigmoid(out)\n",
    "\n",
    "#out1=tf.nn.dropout(out1,0.75)\n",
    "\n",
    "cost = tf.reduce_mean(( (labels * tf.log(out1)) + ((1 - labels) * tf.log(1.0 - out1)) ) * -1)\n",
    "#cost=tf.reduce_mean(tf.squared_difference(out1,labels))\n",
    "#cost=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(labels,tf.float32),logits=out1))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cost)           \n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "   \n",
    "    for i in range(1000):\n",
    "        res,_=sess.run([cost,train_step],feed_dict={x:images2,y:labels})\n",
    "        if i%100 == 0:\n",
    "            print (res)\n",
    "    print (\"Validating training dataset\")\n",
    "    res=sess.run([out1],feed_dict={x:images2})\n",
    "    print(np.round(res)) \n",
    "    conv1_output=sess.run([conv_output],feed_dict={x:images2})\n",
    "    conv2_output=sess.run([conv_output2],feed_dict={x:images2})\n",
    "    conv3_output=sess.run([conv_output3],feed_dict={x:images2})\n",
    "    conv1_weights=sess.run([W])\n",
    "    conv2_weights=sess.run([W1])\n",
    "    conv3_weights=sess.run([W2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_min = np.min(conv1_weights)\n",
    "w_max = np.max(conv1_weights)\n",
    "outt=np.array(conv1_weights)\n",
    "print(outt.shape)\n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "columns = 4\n",
    "for i in range(32):\n",
    "    plt.subplot(32 / columns + 1, columns, i + 1)\n",
    "    plt.imshow(outt[0,:,:,0,i],vmin=w_min, vmax=w_max,interpolation='nearest', cmap='seismic')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outt=np.array(conv1_output)\n",
    "print(outt.shape)\n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "columns = 4\n",
    "for i in range(32):\n",
    "    plt.subplot(32 / columns + 1, columns, i + 1)\n",
    "    plt.imshow(outt[0,1,:,:,i])\n",
    "plt.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_min = np.min(conv2_weights)\n",
    "w_max = np.max(conv2_weights)\n",
    "outt=np.array(conv2_weights)\n",
    "print(outt.shape)\n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "columns = 4\n",
    "for i in range(64):\n",
    "    plt.subplot(64 / columns + 1, columns, i + 1)\n",
    "    plt.imshow(outt[0,:,:,0,i],vmin=w_min, vmax=w_max,interpolation='nearest', cmap='seismic')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outt=np.array(conv2_output)\n",
    "print(outt.shape)\n",
    "\n",
    "plt.figure(figsize=(20,50))\n",
    "columns = 4\n",
    "for i in range(64):\n",
    "    plt.subplot(64 / columns + 1, columns, i + 1)\n",
    "    plt.imshow(outt[0,1,:,:,i])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outt=np.array(conv3_output)\n",
    "print(outt.shape)\n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "columns = 4\n",
    "for i in range(16):\n",
    "    plt.subplot(16 / columns + 1, columns, i + 1)\n",
    "    plt.imshow(outt[0,1,:,:,i])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "con=session.run(conv_output,feed_dict={x:images2})\n",
    "outt=np.array(con)\n",
    "print(outt.shape)\n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "columns = 4\n",
    "for i in range(32):\n",
    "    plt.subplot(32 / columns + 1, columns, i + 1)\n",
    "    plt.imshow(outt[1,:,:,i])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
